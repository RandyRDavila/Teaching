{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilayered Perceptron: The Start of Deep Learning\n",
    "In this notebook we implement a multilayered perceptron model in order to classify species of flower based off of measurements given in the [iris data set](https://en.wikipedia.org/wiki/Iris_flower_data_set). Our task is to predict the species of flower based off of measurements of sepeal length and width, and measurements of petal length and width. \n",
    "\n",
    "You will need to add the following packages:\n",
    " * CSV [documentation](https://juliadata.github.io/CSV.jl/stable/)\n",
    "\n",
    "\n",
    "\n",
    "* Setosa\n",
    "<img src=\"setosa.jpg\" alt=\"Drawing\" style=\"width: 150px; height: 150px\"/>\n",
    "\n",
    "* Versicolor\n",
    "<img src=\"versicolor.jpg\" alt=\"Drawing\" style=\"width: 150px;\"/>\n",
    "\n",
    "* Virginica\n",
    "<img src=\"virginica.jpg\" alt=\"Drawing\" style=\"width: 150px;\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV\n",
    "\"\"\" Provided you have a saved and valid .csv file in your current working directory, you may \n",
    "    load this file as a Dataframe using the following syntax. \n",
    "\"\"\"\n",
    "iris = CSV.read(\"iris_data.csv\")\n",
    "println(iris)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We next construct data matrices $X$ and $Y$. The matrix $X$ will be the $4\\times150$ matrix, where each column corresponds to the measurements for a given flower. The $Y$ matrix will be the $3\\times150$ matrix, where each $i$th column corresponds to the one-hot encoding of the label for the $i$th flower. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = zeros(4, 150)\n",
    "Y = zeros(3, 150)\n",
    "\n",
    "for i = 1:150\n",
    "    for j = 1:4\n",
    "        X[j, i] = iris[i, j]\n",
    "        if iris[i , 5] == \"setosa\"\n",
    "            Y[1, i] = 1.0\n",
    "        elseif iris[i, 5] == \"versicolor\"\n",
    "            Y[2, i] = 1.0\n",
    "        else\n",
    "            Y[3, i] = 1.0\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Network Architecture \n",
    "For our purposes, we will build a multilayered perceptron with $4$ input notes, $2$ hidden layers, and $3$ output nodes. \n",
    "\n",
    "<img src=\"multilayerPerceptron.jpg\" alt=\"Drawing\" style=\"width: 450px;\"/>\n",
    "\n",
    "Each node in our network will have two phases, preactivation, and postactivation. The preactivation phase consists of a weighted linear combination of postactivation values in the previous layer. The postactivation values consists of passing the preactivation value through an activation function elementwise. For our activation function, we will use the sigmoid function:\n",
    "\n",
    "\n",
    "* Sigmoid Function\n",
    "$$\n",
    "\\sigma(s) = \\frac{1}{1+e^{-s}}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sigmoid function and its derivative\n",
    "σ(s) = 1/(1+exp(-s))\n",
    "dσ(s) = σ(s)*(1 - σ(s))\n",
    "\n",
    "# Define softmax function\n",
    "softmax(a, i) = exp(a[i])/(sum(exp(a[j]) for j = 1:length(a)))\n",
    "\n",
    "# Define cross-entropy loss function\n",
    "L(O, y) = -sum(y[i]*log(O[i]) for i = 1:length(y))\n",
    "\n",
    "# Define Hadamard Product\n",
    "hadamard(x,y) = [x[i]*y[i] for i = 1:length(x)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function forward_propagation(x, y, W, b)\n",
    "    a1 = copy(x)\n",
    "    z2 = W[1]*a1 + b[1]\n",
    "    a2 = σ.(z2)\n",
    "    \n",
    "    z3 = W[2]*a2 + b[2]\n",
    "    a3 = σ.(z3)\n",
    "    \n",
    "    z4 = W[3]*a3 + b[3]\n",
    "    a4 = σ.(z4)\n",
    "    \n",
    "    a = [a1, a2, a3, a4]\n",
    "    z = [[0.0], z2, z3, z4]\n",
    "    O = [softmax(a4, i) for i = 1:length(a4)]\n",
    "    loss = L(O, y)\n",
    "    return a, z, O, loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function backpropagation(x, y, W, b)\n",
    "    a, z, O, loss = forward_propagation(x, y, W, b)\n",
    "    δ4 = a[4] - y\n",
    "    δ3 = hadamard(W[3]'*δ4, dσ.(z[3]))\n",
    "    δ2 = hadamard(W[2]'*δ3, dσ.(z[2]))\n",
    "    δ = [[0.0], δ2, δ3, δ4]\n",
    "    return a, δ\n",
    "end\n",
    "\n",
    "function ∇L(x, y, W, b)\n",
    "\n",
    "    a, δ = backpropagation(x, y, W, b)\n",
    "    \n",
    "    db1 = copy(δ[2])\n",
    "    db2 = copy(δ[3])\n",
    "    db3 = copy(δ[4])\n",
    "    \n",
    "    dW1 = δ[2]*a[1]'\n",
    "    dW2 = δ[3]*a[2]'\n",
    "    dW3 = δ[4]*a[3]'\n",
    "    return [db1, db2, db3], [dW1, dW2, dW3]\n",
    "end\n",
    "\n",
    "\n",
    "function gradient_descent!(x, y, W, b, α)\n",
    "    db, dW = ∇L(x, y, W, b)\n",
    "    for i = 1:length(W)\n",
    "        W[i] -= α*dW[i]\n",
    "        b[i] -= α*b[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function mini_batch_∇L(train_data, train_label, W, b, m)\n",
    "\n",
    "    i = rand(1:100)\n",
    "    a, δ = backpropagation(train_data[:,i], train_label[:,i], W, b)\n",
    "    \n",
    "    db1 = δ[2]\n",
    "    db2 = δ[3]\n",
    "    db3 = δ[4]\n",
    "    \n",
    "    dW1 = δ[2]*a[1]'\n",
    "    dW2 = δ[3]*a[2]'\n",
    "    dW3 = δ[4]*a[3]'\n",
    "    \n",
    "    for _ in 1:m\n",
    "        j = rand(1:100)\n",
    "        a, δ = backpropagation(train_data[:,j], train_label[:,j], W, b)\n",
    "    \n",
    "        db1 += copy(δ[2])\n",
    "        db2 += copy(δ[3])\n",
    "        db3 += copy(δ[4])\n",
    "    \n",
    "        dW1 += δ[2]*a[1]'\n",
    "        dW2 += δ[3]*a[2]'\n",
    "        dW3 += δ[4]*a[3]'\n",
    "    end\n",
    "    \n",
    "    return [db1/m, db2/m, db3/m], [dW1/m, dW2/m, dW3/m]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function stochastic_gradient_descent!(train_data, train_label, W, b, α, m)\n",
    "    db , dW = mini_batch_∇L(train_data, train_label, W, b, m)\n",
    "    for i = 1:length(W)\n",
    "        W[i] -= α*dW[i]\n",
    "        b[i] -= α*b[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weight matrices \n",
    "W1 = rand(5, 4)\n",
    "W2 = rand(5, 5)\n",
    "W3 = rand(3, 5)\n",
    "W = [W1, W2, W3]\n",
    "\n",
    "# Initialize bias \n",
    "b1 = -1*ones(5)\n",
    "b2 = -1*ones(5)\n",
    "b3 = -1*ones(3)\n",
    "b = [b1, b2, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_prediction(i)\n",
    "    output = forward_propagation(X[:,i], Y[:,i], W, b)[3]\n",
    "    println(\"      setosa       |     versicolor       |     virginica\")\n",
    "    println(\"----------------------------------------------------------------\")\n",
    "    println(output[1],\" | \", output[2], \"  |  \", output[3])\n",
    "end\n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in 1:100000\n",
    "    stochastic_gradient_descent!(train_data, train_label, W, b, 0.38, 23)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_prediction(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
