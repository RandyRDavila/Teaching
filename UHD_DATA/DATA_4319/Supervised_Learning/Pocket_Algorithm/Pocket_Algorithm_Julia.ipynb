{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Perceptron Pocket Algorithm\n",
    "\n",
    "Many instances of data are linearily seperable, but only after removing *noise*; the following image is one such example. \n",
    "\n",
    "<img src=\"linear_noisy_data.png\" alt=\"Drawing\" style=\"width: 300px;\"/>\n",
    "\n",
    "Such data is actually encountered often: even though a linear classifier seems appropiate, the data may not be linearily seperable because of outliers or noise. Notably, we proved that the perceptron learning algorithm (PLA) will not converge whenever the training data is not linearily seperable. Thus, we must exclude the PLA from our toolkit in this instance. More specifically, we need solve the combinatorial optimization problem:\n",
    "\n",
    "$$\n",
    "\\min_{\\boldsymbol{w}\\in\\mathbb{R}^{d+1}}\\frac{1}{N}\\sum_{i=n}^{N}||\\text{sign}(w^{T}\\boldsymbol{x}_n) \\neq y_n||.\n",
    "$$\n",
    "\n",
    "Note the in-sample error is given by:\n",
    "\n",
    "$$\n",
    "E_{\\text{in}}(\\boldsymbol{w}) = \\frac{1}{N}\\sum_{i=n}^{N}||\\text{sign}(w^{T}\\boldsymbol{x}_n) \\neq y_n||.\n",
    "$$\n",
    "\n",
    "In general, determining the solution the above mentioned optimization problemn is NP-hard. Thus, we will only approximate the solution the minimization problem. Our algorithm is called the *pocket algorithm*. Essentially, the pocket algorithm keeps in its 'pocket' the best weight vector encountered up to iteration $t$ in PLA. At the end of the algorithm, the best weight vector will be reported as the final hypothesis. \n",
    "\n",
    "**The Pocket Algorithm**\n",
    "1. Set the pocket weight vector $\\hat{\\boldsymbol{w}}$ to $\\boldsymbol{w}(0)$ of PLA.\n",
    "2. **for** $t=0,\\dots,T-1$ **do**\n",
    " * $     $ $       $ Run PLA for one update to obtain $\\boldsymbol{w}(t+1)$.\n",
    " * $     $ $       $ Evaluate $E_{\\text{in}}(\\boldsymbol{w}(t+1))$.\n",
    " * $     $ $       $ if $\\boldsymbol{w}(t+1)$ is better than $\\hat{\\boldsymbol{w}}$ in terms of     $E_{\\text{in}}(\\boldsymbol{w}(t+1))$, set $\\hat{\\boldsymbol{w}}$ to $\\boldsymbol{w}(t+1)$.\n",
    "6. Return $\\hat{\\boldsymbol{w}}$\n",
    "\n",
    "The original PLA only checks some of the examples using $\\boldsymbol{w}(t)$ to identify $(\\boldsymbol{x}(t), y(t))$ in each iteration, while the pocket algorithm needs an additional step that evaluates *all* examples using $\\boldsymbol{w}(t+1)$ to get $E_{\\text{in}}(\\boldsymbol{w}(t+1))$. This additional step makes the pocket algorithm much slower that PLA. Nevertheless, it is a useful algorithm to know about. We will next implement the pocket algorithm to classify hand written images of digits in $\\{1,5\\}$ from the famous *mnist data set*. \n",
    "\n",
    "## MNIST Data Set\n",
    "\n",
    "The MNIST data set consists of $70000$ images of hand written digits, $60000$ of which are typically used as labeled training examples, where the other $10000$ are used for testing your learning model on. The following picture represent a sample of some of the images.\n",
    "\n",
    "<img src=\"MnistExamples.png\" alt=\"Drawing\" style=\"width: 500px;\"/>\n",
    "\n",
    "\n",
    "To access this data set, as well as view the data as an image, we will need the following packages:\n",
    " * MLDatasets [documentation](https://github.com/JuliaML/MLDatasets.jl)\n",
    " * Images, TestImages, ImageMagicIO [documentation](https://juliaimages.org/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLDatasets\n",
    "using Images\n",
    "using TestImages\n",
    "\n",
    "train_x, train_y = MNIST.traindata()\n",
    "test_x,  test_y  = MNIST.testdata();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The data structures train_x and test_x are stored as 3 dimensional tensors. \n",
    " \n",
    " \n",
    " \n",
    "<img src=\"order-3-tensor.png\" alt=\"Drawing\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 60000)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the dimensions of the train_x tensor.\n",
    "size(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the dimensions of the training vector. This should match the depth of out training \n",
    "# tensor. \n",
    "size(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28×28 Array{N0f8,2} with eltype Normed{UInt8,8}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0    …  0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.216  0.533  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0    …  0.0    0.675  0.992  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.071  0.886  0.992  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.671  0.992  0.992  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.118     0.859  0.992  0.831  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.141     0.992  0.992  0.529  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.369  …  0.992  0.992  0.518  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.604     0.992  0.957  0.063  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.012  0.667     0.992  0.522  0.0    0.0  0.0  0.0\n",
       " ⋮                        ⋮             ⋱                       ⋮            \n",
       " 0.0  0.0  0.0  0.0  0.0  0.494  0.992     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.533  0.992     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.686  0.882     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.102  0.675     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.651  0.992  …  0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  1.0    0.949     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.969  0.765     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.498  0.251     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0    …  0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the the shape of the elements in the tensor slices.\n",
    "train_x[:,:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image in the is comprised of a $28\\times 28$ grey scaled grid of pixel values. These values are floating point numbers in the interval $(0,1)$, where darker pixels will have values closer to $1$ and lighter pixels will have values closer to $0$. The following image represents one such example. \n",
    "\n",
    "<img src=\"MNIST-Matrix.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28×28 Array{N0f8,2} with eltype Normed{UInt8,8}:\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0    …  0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.216  0.533  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0    …  0.0    0.675  0.992  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.071  0.886  0.992  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.671  0.992  0.992  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.118     0.859  0.992  0.831  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.141     0.992  0.992  0.529  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.369  …  0.992  0.992  0.518  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.604     0.992  0.957  0.063  0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.012  0.667     0.992  0.522  0.0    0.0  0.0  0.0\n",
       " ⋮                        ⋮             ⋱                       ⋮            \n",
       " 0.0  0.0  0.0  0.0  0.0  0.494  0.992     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.533  0.992     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.686  0.882     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.102  0.675     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.651  0.992  …  0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  1.0    0.949     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.969  0.765     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.498  0.251     0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0    …  0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0\n",
       " 0.0  0.0  0.0  0.0  0.0  0.0    0.0       0.0    0.0    0.0    0.0  0.0  0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What are the entries in each of these 28x28 matrices??\n",
    "train_x[:,:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the label of the above matrix. \n",
    "train_y[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "UndefVarError",
     "evalue": "UndefVarError: savefig not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: savefig not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[7]:3"
     ]
    }
   ],
   "source": [
    "# View the image\n",
    "colorview(Gray, train_x[:,:,1]')\n",
    "savefig(\"MNIST_Example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "errors (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the pocket algorithm to classify images of numbers in the set {1,5}. Note that this is a\n",
    "# binary classification problem, even though the input vectors have dimension much larger than\n",
    "# we have seen before. \n",
    "\n",
    "# Reduce the dimension of the input data\n",
    "pocket_train_x = []\n",
    "pocket_train_y = []\n",
    "for i = 1:60000\n",
    "    if train_y[i] == 1 || train_y[i] == 5\n",
    "        push!(pocket_train_x, reshape(train_x[:,:,i], 784))\n",
    "        push!(pocket_train_y, train_y[i] == 1 ? 1 : -1)\n",
    "    end\n",
    "end\n",
    "\n",
    "# Handy-dandy sign function\n",
    "function sign(w, x)\n",
    "    x = push!(copy(x), 1.0)\n",
    "    return w'x > 0 ? 1 : -1\n",
    "end\n",
    "\n",
    "# Define the in-sample error\n",
    "function errors(w)\n",
    "    return sum([sign(w, pocket_train_x[i])!= pocket_train_y[i] ? 1 : 0 \n",
    "            for i = 1:size(pocket_train_x)[1]])/size(pocket_train_x)[1]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pocket algorithm on T iterations\n",
    "function pocket_algorithm(T)\n",
    "    w = randn(785)\n",
    "    w_hat = copy(w)\n",
    "    for i = 1:T\n",
    "        for j = 1:size(pocket_train_x)[1]\n",
    "            if sign(w, pocket_train_x[j]) != pocket_train_y[j]\n",
    "                w += pocket_train_y[j]*push!(copy(pocket_train_x[j]),1.0)\n",
    "            end\n",
    "        end\n",
    "        if errors(w) < errors(w_hat)\n",
    "                    w_hat = copy(w)\n",
    "        end\n",
    "    end\n",
    "    return w_hat\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try it!\n",
    "#w = rand(785)\n",
    "w_new = pocket_algorithm(500);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indicies = []\n",
    "for i in 1:size(test_y)[1]\n",
    "    if test_y[i] == 1 || test_y[i] == 5\n",
    "        push!(indicies, (i, test_y[i]))\n",
    "    end\n",
    "end        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function check_value(i)\n",
    "    println(\"Predicted value:\", \n",
    "        sign(w_new, reshape(test_x[:,:,indicies[i][1]], 784)) == 1 ? 1 : 5, \"\\n\")\n",
    "    println(\"Labeled value:\", test_y[indicies[i][1]], \"\\n\")\n",
    "    println(\"Image:\")\n",
    "    colorview(Gray, test_x[:,:,indicies[i][1]]')\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_value(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_value(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_value(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_value(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_value(323)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_value(129)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_value(1700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_value(1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.5",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
